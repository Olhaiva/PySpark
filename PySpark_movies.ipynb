{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLCsmVH5GRTpDE1PaQIX5Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Olhaiva/PySpark/blob/main/PySpark_movies.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwLpS1-RWFSc",
        "outputId": "dcbfef74-6437-4d36-a001-d413ef77b8fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317145 sha256=cc2ce5565931c4489fcdc64327391ddfd6cdc27ccb36571c502ccfbcf65b9f00\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.0\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# PYSPARK\n",
        "!pip install pyspark\n",
        "\n",
        "# Import modules\n",
        "from pyspark import SparkConf\n",
        "from pyspark.sql import SparkSession, Window\n",
        "import pyspark.sql.types as t\n",
        "import pyspark.sql.functions as f\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount ('/content/drive')\n",
        "\n",
        "# Creating a sparksession\n",
        "spark_session = (SparkSession.builder\n",
        "                             .master (\"local\")\n",
        "                             .appName (\"task app\")\n",
        "                             .config (conf=SparkConf())\n",
        "                             .getOrCreate())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading data to df\n",
        "path ='/content/drive/MyDrive/Diploma_spark/title.akas.tsv/data.tsv'\n",
        "title_akas_df = spark_session.read.csv(path, sep='\\t',header=True)\n",
        "\n",
        "path ='/content/drive/MyDrive/Diploma_spark/name.basics.tsv.gz/data.tsv'\n",
        "name_basics_df = spark_session.read.csv(path, sep='\\t',header=True)\n",
        "\n",
        "path ='/content/drive/MyDrive/Diploma_spark/title.basics.tsv/data.tsv'\n",
        "title_basics_df = spark_session.read.csv(path, sep='\\t',header=True)\n",
        "\n",
        "path ='/content/drive/MyDrive/Diploma_spark/title.principals.tsv/data.tsv'\n",
        "title_principals_df = spark_session.read.csv(path, sep='\\t',header=True).filter(f.col('characters')!='\\\\N').select('tconst','nconst', 'characters')\n",
        "\n",
        "path ='/content/drive/MyDrive/Diploma_spark/title.episode.tsv/data.tsv'\n",
        "title_episode_df = spark_session.read.csv(path, sep='\\t',header=True)\n",
        "\n",
        "path ='/content/drive/MyDrive/Diploma_spark/title.ratings.tsv/data.tsv'\n",
        "title_ratings_df = spark_session.read.csv(path, sep='\\t',header=True)"
      ],
      "metadata": {
        "id": "1AVGmluaYjuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Task 1. Get all titles of series/movies etc. that are available in Ukrainian\n",
        "https://www.imdb.com/interfaces/\n",
        "title.akas.tsv.gz\n",
        "\n",
        "    title (string) – the localized title\n",
        "    language (string) - the language of the title\n",
        "'''\n",
        "# Transforming data df for 1 task\n",
        "task1_df = title_akas_df.select('title').filter((f.col('language')=='ua') | (f.col('region')=='UA')).dropDuplicates()\n",
        "\n",
        "# writing results to the file\n",
        "path = '/content/drive/MyDrive/Diploma_spark/'\n",
        "path_for_task1= path + 'task1'\n",
        "task1_df.write.csv(path_for_task1, header=True, mode='overwrite')\n"
      ],
      "metadata": {
        "id": "PrzGSenq6Kie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Task 2. Get the list of peopleʼs names, who were born in the 19th century.\n",
        "https://www.imdb.com/interfaces/\n",
        "name.basics.tsv.gz\n",
        "    primaryName (string)– name by which the person is most often credited\n",
        "    birthYear – in YYYY format\n",
        "    primaryProfession (array of strings)– the top-3 professions of the person\n",
        "'''\n",
        "# transforming data df for 2 task (choosing columns, modifying types)\n",
        "task2_df = name_basics_df.select('primaryName','birthYear')\\\n",
        "                         .withColumn('birthYear',f.col('birthYear').cast(t.IntegerType()))\\\n",
        "                         .select('primaryName')\\\n",
        "                         .filter(f.col('birthYear').between(1800, 1900))\n",
        "\n",
        "# writing results to the file\n",
        "path_for_task2= path +'task2'\n",
        "task2_df.write.csv(path_for_task2, header=True, mode='overwrite')"
      ],
      "metadata": {
        "id": "aRl45XU04E5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Task 3\n",
        "Get titles of all movies that last more than 2 hours.\n",
        "\n",
        "title.basics.tsv.gz\n",
        "    titleType (string) – the type/format of the title (e.g. movie, short, tvseries, tvepisode, video, etc)\n",
        "    originalTitle (string) - original title, in the original language\n",
        "    runtimeMinutes – primary runtime of the title, in minutes\n",
        "'''\n",
        "# Transforming data for 3 task\n",
        "task3_df = title_basics_df.select('originalTitle')\\\n",
        "                          .filter(f.col('titleType')=='movie')\\\n",
        "                          .filter(f.col('runtimeMinutes').cast(t.IntegerType()) >= 120)\n",
        "\n",
        "# writing results to the file\n",
        "path_for_task3= path +'task3'\n",
        "task3_df.write.csv(path_for_task3, header=True, mode='overwrite')"
      ],
      "metadata": {
        "id": "F6xvp_1EJV3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Task 4\n",
        " Get names of people, corresponding movies/series and characters they\n",
        "played in those films.\n",
        "\n",
        "title.principals.tsv.gz – Contains the principal cast crew for titles\n",
        "    tconst (string) - alphanumeric unique identifier of the title\n",
        "    nconst (string) - alphanumeric unique identifier of the name/person\n",
        "    characters (string) - the name of the character played if applicable, else 'N'\n",
        "\n",
        "title.basics.tsv.gz\n",
        "    tconst (string) - alphanumeric unique identifier of the title\n",
        "    originalTitle (string) - original title, in the original language\n",
        "\n",
        "name.basics.tsv.gz – Contains the following information for names:\n",
        "    nconst (string) - alphanumeric unique identifier of the name person\n",
        "    primaryName (string)– name by which the person is most often credited\n",
        "'''\n",
        "# transforning data for 4 task\n",
        "n_df = name_basics_df.select('nconst','primaryName')\n",
        "t_df = title_basics_df.select('tconst','originalTitle')\n",
        "task4_df = title_principals_df.join(t_df, on='tconst', how='inner')\\\n",
        "                              .join(n_df, on='nconst', how='inner')\n",
        "task4_df = task4_df.select('primaryName', 'originalTitle', 'characters')\n",
        "\n",
        "# writing results to the file\n",
        "path_for_task4= path +'task4'\n",
        "task4_df.write.csv(path_for_task4, header=True, mode='overwrite')\n"
      ],
      "metadata": {
        "id": "xrzX9MxGW7CN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Task 5\n",
        "Get information about how many adult movies/series etc. there are per\n",
        "region. Get the top 100 of them from the region with the biggest count to\n",
        "the region with the smallest one.\n",
        "\n",
        "title.akas.tsv.gz\n",
        "    titleId (string) - a tconst, an alphanumeric unique identifier of the title\n",
        "    region (string) - the region for this version of the title\n",
        "\n",
        "title.basics.tsv.gz - Contains the following information for titles:\n",
        "•\ttconst (string) - alphanumeric unique identifier of the title\n",
        "•\tisAdult (boolean) - 0: non-adult title; 1: adult title\n",
        "'''\n",
        "# Creating dataframe for 5 task\n",
        "region_df = title_akas_df.select(f.col('titleId').alias('tconst'),'region')\n",
        "adult_df = title_basics_df.select('tconst')\\\n",
        "                          .filter(f.col('isAdult')=='1')\n",
        "\n",
        "region_join_df = region_df.join(adult_df, on='tconst', how='inner')\n",
        "task5_df = region_join_df.groupby('region').count()\n",
        "task5_df = task5_df.orderBy(f.desc('count')).limit(100)\n",
        "\n",
        "# writing results to the file\n",
        "path_for_task5= path +'task5'\n",
        "task5_df.write.csv(path_for_task5, header=True, mode='overwrite')"
      ],
      "metadata": {
        "id": "1eoTYuIBP73E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Task 6\n",
        "Get information about how many episodes in each TV Series. Get the top\n",
        "50 of them starting from the TV Series with the biggest quantity of\n",
        "episodes.\n",
        "\n",
        "title.episode.tsv.gz – Contains the tv episode information. Fields include:\n",
        "    tconst (string) - alphanumeric identifier of episode\n",
        "    parentTconst (string) - alphanumeric identifier of the parent TV Series\n",
        "\n",
        "title.basics.tsv.gz - Contains the following information for titles:\n",
        "    tconst (string) - alphanumeric unique identifier of the title\n",
        "    titleType (string) – the type/format of the title (e.g. movie, short, tvseries, tvepisode, video, etc)\n",
        "    primaryTitle (string) – the more popular title / the title used by the filmmakers on promotional materials at the point of release\n",
        "'''\n",
        "\n",
        "# Creating dataframe for 5 task\n",
        "episode_df = title_episode_df.select('tconst','parentTconst')\\\n",
        "                             .groupby('parentTconst').count()\n",
        "\n",
        "titles_df = title_basics_df.select('tconst','primaryTitle')\\\n",
        "                           .filter(f.col('titleType') == 'tvSeries')\n",
        "\n",
        "task6_df = episode_df.join(titles_df, episode_df['parentTconst']==titles_df['tconst'], how='left')\\\n",
        "                     .select('primaryTitle','count')\\\n",
        "                     .orderBy(f.desc('count'))\\\n",
        "                     .limit(50)\n",
        "\n",
        "# writing results to the file\n",
        "path_for_task6= path + 'task6'\n",
        "task6_df.write.csv(path_for_task6, header=True, mode='overwrite')\n"
      ],
      "metadata": {
        "id": "eFdgHEBxxkJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Task 7.\n",
        "Get 10 titles of the most popular movies/series etc. by each decade.\n",
        "\n",
        "title.ratings.tsv.gz – Contains the IMDb rating and votes information for titles\n",
        "    tconst (string) - alphanumeric unique identifier of the title\n",
        "    averageRating – weighted average of all the individual user ratings\n",
        "    numVotes - number of votes the title has received\n",
        "\n",
        "title.basics.tsv.gz - Contains the following information for titles:\n",
        "\n",
        "    tconst (string) - alphanumeric unique identifier of the title\n",
        "    titleType (string) – the type/format of the title (e.g. movie, short, tvseries, tvepisode, video, etc)\n",
        "    primaryTitle (string) – the more popular title / the title used by the filmmakers on promotional materials at the point of release\n",
        "    startYear (YYYY) – represents the release year of a title. In the case of TV Series, it is the series start year\n",
        "    endYear (YYYY) – TV Series end year. ‘\\\\N’ for all other title types\n",
        "'''\n",
        "# Creating df\n",
        "rating_df = title_ratings_df.select('tconst','averageRating','numVotes')\\\n",
        "                            .withColumn('averageRating', f.col('averageRating').cast(t.FloatType()))\\\n",
        "                            .withColumn('numVotes', f.col('numVotes').cast(t.IntegerType()))\n",
        "\n",
        "years_df = title_basics_df.select('tconst','originalTitle', 'startYear')\\\n",
        "                          .withColumn('startYear', f.col('startYear').cast(t.IntegerType()))\\\n",
        "                          .withColumn('decade', (f.floor(f.col('startYear')/10)*10).cast(t.IntegerType()))\\\n",
        "                          .drop('startYear')\n",
        "\n",
        "task7_df = rating_df.join(years_df, on='tconst', how='inner')\n",
        "\n",
        "min_decade = task7_df.agg(f.min('decade')).collect()[0][0]\n",
        "max_decade = task7_df.agg(f.max('decade')).collect()[0][0]\n",
        "\n",
        "from pyspark.sql.dataframe import DataFrame\n",
        "schema = t.StructType([\n",
        "    t.StructField('decade', t.IntegerType(), True),\n",
        "    t.StructField('originalTitle', t.StringType(), True),\n",
        "    t.StructField('averageRating', t.FloatType(), True),\n",
        "    t.StructField('numVotes', t.FloatType(), True),\n",
        "    t.StructField('order', t.IntegerType(), True)])\n",
        "\n",
        "result_df = spark_session.createDataFrame([],schema)\n",
        "\n",
        "window = Window.orderBy(f.desc('averageRating'), f.desc('numVotes')).partitionBy('decade')\n",
        "\n",
        "for d in range(min_decade, max_decade+1, 10):\n",
        "    auxiliary_df = task7_df.filter(f.col('decade')==d)\\\n",
        "                           .select('decade', 'originalTitle', 'averageRating', 'numVotes')\\\n",
        "                           .orderBy(f.desc('averageRating'), f.desc('numVotes'))\\\n",
        "                           .limit(10)\n",
        "\n",
        "    auxiliary_df = auxiliary_df.withColumn('order_byrow_numder', f.row_number().over(window))\n",
        "\n",
        "    if isinstance(result_df, DataFrame):\n",
        "        result_df = result_df.union(auxiliary_df)\n",
        "    else:\n",
        "        result_df = auxiliary_df\n",
        "\n",
        "# writing results to the file\n",
        "path_for_task7='/content/drive/MyDrive/Diploma_spark/task7'\n",
        "result_df.write.csv(path_for_task7, header=True, mode='overwrite')"
      ],
      "metadata": {
        "id": "tt-pQdgDAOs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Task 8.\n",
        "Get 10 titles of the most popular movies/series etc. by each genre.\n",
        "\n",
        "title.ratings.tsv.gz – Contains the IMDb rating and votes information for titles\n",
        "    tconst (string) - alphanumeric unique identifier of the title\n",
        "    averageRating – weighted average of all the individual user ratings\n",
        "    numVotes - number of votes the title has received\n",
        "\n",
        "title.basics.tsv.gz - Contains the following information for titles:\n",
        "\n",
        "    tconst (string) - alphanumeric unique identifier of the title\n",
        "    titleType (string) – the type/format of the title (e.g. movie, short, tvseries, tvepisode, video, etc)\n",
        "    primaryTitle (string) – the more popular title / the title used by the filmmakers on promotional materials at the point of release\n",
        "    genres (string array) – includes up to three genres associated with the title\n",
        "'''\n",
        "# Creating df\n",
        "genres_df = title_basics_df.select('tconst','originalTitle', 'genres')\n",
        "genres_df = genres_df.withColumn('genres', f.split(genres_df.genres, \",\"))\n",
        "genres_df = genres_df.withColumn('genre', f.explode('genres'))\n",
        "\n",
        "task8_df = rating_df.join(genres_df, on='tconst', how='inner')\n",
        "\n",
        "window = Window.orderBy(f.desc('averageRating'), f.desc('numVotes')).partitionBy('genre')\n",
        "\n",
        "task8_df = task8_df.drop('tconst', 'genres')\\\n",
        "                   .withColumn('order_numder', f.row_number().over(window))\\\n",
        "                   .filter(f.col('order_numder')<=10)\\\n",
        "                   .select('order_numder', 'originalTitle', 'genre')\n",
        "\n",
        "# writing results to the file\n",
        "path_for_task8 = path + 'task8'\n",
        "task8_df.write.csv(path_for_task8, header=True, mode='overwrite')"
      ],
      "metadata": {
        "id": "XS-c_YOa-ssV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}